{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "14.n_grams.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y49cRqTo2M6m"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time\n",
        "\n",
        "plt.style.use(style='seaborn')\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('all-data.csv',encoding = \"ISO-8859-1\", header=None, names = ['Sentiment', 'News Headline'])\n",
        "df.head()"
      ],
      "metadata": {
        "id": "yJxu4MgA5KFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "tNShwg8z5rrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "wcb5AiSc5u00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Sentiment'].value_counts()"
      ],
      "metadata": {
        "id": "T_bPosEd5xfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=df['Sentiment'].values\n",
        "y.shape"
      ],
      "metadata": {
        "id": "KGRC-4nM50Dl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=df['News Headline'].values\n",
        "x.shape"
      ],
      "metadata": {
        "id": "XUHG-sMB5245"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "boMP7jng55Z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train,x_test,y_train,y_test)=train_test_split(x,y,test_size=0.4)"
      ],
      "metadata": {
        "id": "kjHs5L2j586k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "id": "LoduAYUn5_il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "id": "jbGytqWE6Bnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape"
      ],
      "metadata": {
        "id": "TQvOp25t6D1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "id": "3KqqMeoq6GVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "id": "-4L9Xm-o6Ikw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1=pd.DataFrame(x_train)\n",
        "df1=df1.rename(columns={0:'news'})\n",
        "\n",
        "df2=pd.DataFrame(y_train)\n",
        "df2=df2.rename(columns={0:'sentiment'})\n",
        "df_train=pd.concat([df1,df2],axis=1)\n",
        "\n",
        "df_train.head()"
      ],
      "metadata": {
        "id": "TZwI8WC76Kms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.info()"
      ],
      "metadata": {
        "id": "a5vubpUY6Nt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3=pd.DataFrame(x_test)\n",
        "df3=df3.rename(columns={0:'news'})\n",
        "\n",
        "df4=pd.DataFrame(y_test)\n",
        "df4=df2.rename(columns={0:'sentiment'})\n",
        "df_test=pd.concat([df3,df4],axis=1)\n",
        "\n",
        "df_test.head()"
      ],
      "metadata": {
        "id": "J9MFnlma6QtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.info()"
      ],
      "metadata": {
        "id": "4JMsBnpw6VGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#removing punctuations\n",
        "#library that contains punctuation\n",
        "import string\n",
        "string.punctuation"
      ],
      "metadata": {
        "id": "s1rBbNxi6VPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining the function to remove punctuation\n",
        "def remove_punctuation(text):\n",
        "  if(type(text)==float):\n",
        "    return text\n",
        "  ans=\"\"  \n",
        "  for i in text:     \n",
        "    if i not in string.punctuation:\n",
        "      ans+=i    \n",
        "  return ans\n",
        "\n",
        "#storing the puntuation free text in a new column called clean_msg\n",
        "df_train['news']= df_train['news'].apply(lambda x:remove_punctuation(x))\n",
        "df_test['news']= df_test['news'].apply(lambda x:remove_punctuation(x))\n"
      ],
      "metadata": {
        "id": "Zrv5o-iU6VTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()\n",
        "#punctuations are removed from news column in train dataset"
      ],
      "metadata": {
        "id": "bDPi3Xo-6dnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "sClplbb96dqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "ehY5pPxB6dtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#method to generate n-grams:\n",
        "#params:\n",
        "#text-the text for which we have to generate n-grams\n",
        "#ngram-number of grams to be generated from the text(1,2,3,4 etc., default value=1)\n",
        "\n",
        "\n",
        "def generate_N_grams(text,ngram=1):\n",
        "  words=[word for word in text.split(\" \") if word not in set(stopwords.words('english'))]  \n",
        "  print(\"Sentence after removing stopwords:\",words)\n",
        "  temp=zip(*[words[i:] for i in range(0,ngram)])\n",
        "  ans=[' '.join(ngram) for ngram in temp]\n",
        "  return ans\n",
        "    "
      ],
      "metadata": {
        "id": "POsQnQO66dyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sample!\n",
        "generate_N_grams(\"The sun rises in the east\",3)"
      ],
      "metadata": {
        "id": "rCY--WTe6VXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "YN5btnJ16rIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positiveValues=defaultdict(int)\n",
        "negativeValues=defaultdict(int)\n",
        "neutralValues=defaultdict(int)\n",
        "#get the count of every word in both the columns of df_train and df_test dataframes"
      ],
      "metadata": {
        "id": "zzPpOTtQ6rLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get the count of every word in both the columns of df_train and df_test dataframes where sentiment=\"positive\"\n",
        "for text in df_train[df_train.sentiment==\"positive\"].news:\n",
        "  for word in generate_N_grams(text):\n",
        "    positiveValues[word]+=1\n",
        "\n",
        "#get the count of every word in both the columns of df_train and df_test dataframes where sentiment=\"negative\"\n",
        "for text in df_train[df_train.sentiment==\"negative\"].news:\n",
        "  for word in generate_N_grams(text):\n",
        "    negativeValues[word]+=1\n",
        "\n",
        "#get the count of every word in both the columns of df_train and df_test dataframes where sentiment=\"neutral\"\n",
        "for text in df_train[df_train.sentiment==\"neutral\"].news:\n",
        "  for word in generate_N_grams(text):\n",
        "    neutralValues[word]+=1"
      ],
      "metadata": {
        "id": "Kr27Z0yB6rOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positiveValues\n",
        "#output is a dictionary-list of words in news column and the count of each of these words in train dataset where sentiment=positive"
      ],
      "metadata": {
        "id": "B4RRmdfw6rSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positiveValues.items()\n",
        "#o/p is a dictionary with the word in news column as key and its count within the train dataset as its corresponding value"
      ],
      "metadata": {
        "id": "Psiep2vS6rVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#focus on more frequently occuring words for every sentiment=>\n",
        "#sort in DO wrt 2nd column in each of positiveValues,negativeValues and neutralValues\n",
        "\n",
        "df_positive=pd.DataFrame(sorted(positiveValues.items(),key=lambda x:x[1],reverse=True))\n",
        "df_negative=pd.DataFrame(sorted(negativeValues.items(),key=lambda x:x[1],reverse=True))\n",
        "df_neutral=pd.DataFrame(sorted(neutralValues.items(),key=lambda x:x[1],reverse=True))"
      ],
      "metadata": {
        "id": "TFHH9Mwo6V3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd1=df_positive[0][:10]\n",
        "pd2=df_positive[1][:10]\n",
        "\n",
        "ned1=df_negative[0][:10]\n",
        "ned2=df_negative[1][:10]\n",
        "\n",
        "nud1=df_neutral[0][:10]\n",
        "nud2=df_neutral[1][:10]\n",
        "\n",
        "\n",
        "plt.figure(1,figsize=(16,4))\n",
        "\n",
        "plt.bar(pd1,pd2, color ='green',\n",
        "        width = 0.4)\n",
        " \n",
        "plt.xlabel(\"Words in positive dataframe\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Top 10 words in positive dataframe-UNIGRAM ANALYSIS\")\n",
        "\n",
        "plt.savefig(\"positive-unigram.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Rchdx9-16V80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_positive.head(10)"
      ],
      "metadata": {
        "id": "erA6njg47F3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(1,figsize=(16,4))\n",
        "\n",
        "plt.bar(ned1,ned2, color ='red',\n",
        "        width = 0.4)\n",
        " \n",
        "plt.xlabel(\"Words in negative dataframe\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Top 10 words in negative dataframe-UNIGRAM ANALYSIS\")\n",
        "\n",
        "plt.savefig(\"negative-unigram.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OVVmSF4V7F5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_negative.head(10)"
      ],
      "metadata": {
        "id": "BEooXXiC7LFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(1,figsize=(16,4))\n",
        "\n",
        "plt.bar(nud1,nud2, color ='yellow',\n",
        "        width = 0.4)\n",
        " \n",
        "plt.xlabel(\"Words in neutral dataframe\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Top 10 words in neutral dataframe-UNIGRAM ANALYSIS\")\n",
        "\n",
        "plt.savefig(\"neutral-unigram.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HFOm_P8X7LH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_neutral.head(10)"
      ],
      "metadata": {
        "id": "0qGo362o7S2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positiveValues2=defaultdict(int)\n",
        "negativeValues2=defaultdict(int)\n",
        "neutralValues2=defaultdict(int)\n",
        "#get the count of every word in both the columns of df_train and df_test dataframes"
      ],
      "metadata": {
        "id": "BxLr0_Uy7S5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get the count of every word in both the columns of df_train and df_test dataframes where sentiment=\"positive\"\n",
        "for text in df_train[df_train.sentiment==\"positive\"].news:\n",
        "  for word in generate_N_grams(text,2):\n",
        "    positiveValues2[word]+=1\n",
        "\n",
        "#get the count of every word in both the columns of df_train and df_test dataframes where sentiment=\"negative\"\n",
        "for text in df_train[df_train.sentiment==\"negative\"].news:\n",
        "  for word in generate_N_grams(text,2):\n",
        "    negativeValues2[word]+=1\n",
        "\n",
        "#get the count of every word in both the columns of df_train and df_test dataframes where sentiment=\"neutral\"\n",
        "for text in df_train[df_train.sentiment==\"neutral\"].news:\n",
        "  for word in generate_N_grams(text,2):\n",
        "    neutralValues2[word]+=1"
      ],
      "metadata": {
        "id": "UIfZxgLj7S7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#focus on more frequently occuring words for every sentiment=>\n",
        "#sort in DO wrt 2nd column in each of positiveValues,negativeValues and neutralValues\n",
        "\n",
        "df_positive2=pd.DataFrame(sorted(positiveValues2.items(),key=lambda x:x[1],reverse=True))\n",
        "df_negative2=pd.DataFrame(sorted(negativeValues2.items(),key=lambda x:x[1],reverse=True))\n",
        "df_neutral2=pd.DataFrame(sorted(neutralValues2.items(),key=lambda x:x[1],reverse=True))"
      ],
      "metadata": {
        "id": "F5yC2Bhg7S-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd1bi=df_positive2[0][:10]\n",
        "pd2bi=df_positive2[1][:10]\n",
        "\n",
        "ned1bi=df_negative2[0][:10]\n",
        "ned2bi=df_negative2[1][:10]\n",
        "\n",
        "nud1bi=df_neutral2[0][:10]\n",
        "nud2bi=df_neutral2[1][:10]\n",
        "\n",
        "plt.figure(1,figsize=(16,4))\n",
        "\n",
        "plt.bar(pd1bi,pd2bi, color ='green',\n",
        "        width = 0.4)\n",
        " \n",
        "plt.xlabel(\"Words in positive dataframe\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Top 10 words in positive dataframe-BIGRAM ANALYSIS\")\n",
        "\n",
        "plt.savefig(\"positive-bigram.png\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "x1CMI6ch7TAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_positive2.head(10)"
      ],
      "metadata": {
        "id": "HutizefD7TDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(1,figsize=(16,4))\n",
        "\n",
        "plt.bar(ned1bi,ned2bi, color ='red',\n",
        "        width = 0.4)\n",
        " \n",
        "plt.xlabel(\"Words in negative dataframe\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Top 10 words in negative dataframe-BIGRAM ANALYSIS\")\n",
        "\n",
        "plt.savefig(\"negative-bigram.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1iO40RyD7TFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_negative2.head(10)"
      ],
      "metadata": {
        "id": "-Gs7WoqS7k5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(1,figsize=(16,4))\n",
        "\n",
        "plt.bar(nud1bi,nud2bi, color ='yellow',\n",
        "        width = 0.4)\n",
        " \n",
        "plt.xlabel(\"Words in neutral dataframe\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Top 10 words in neutral dataframe-BIGRAM ANALYSIS\")\n",
        "\n",
        "plt.savefig(\"neutral-bigram.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DSrrnx3l7k8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_neutral2.head(10)"
      ],
      "metadata": {
        "id": "3qWR1ZpA7k_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positiveValues3=defaultdict(int)\n",
        "negativeValues3=defaultdict(int)\n",
        "neutralValues3=defaultdict(int)\n",
        "#get the count of every word in both the columns of df_train and df_test dataframes"
      ],
      "metadata": {
        "id": "s2waipZM7lFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get the count of every word in both the columns of df_train and df_test dataframes where sentiment=\"positive\"\n",
        "for text in df_train[df_train.sentiment==\"positive\"].news:\n",
        "  for word in generate_N_grams(text,3):\n",
        "    positiveValues3[word]+=1\n",
        "\n",
        "#get the count of every word in both the columns of df_train and df_test dataframes where sentiment=\"negative\"\n",
        "for text in df_train[df_train.sentiment==\"negative\"].news:\n",
        "  for word in generate_N_grams(text,3):\n",
        "    negativeValues3[word]+=1\n",
        "\n",
        "#get the count of every word in both the columns of df_train and df_test dataframes where sentiment=\"neutral\"\n",
        "for text in df_train[df_train.sentiment==\"neutral\"].news:\n",
        "  for word in generate_N_grams(text,3):\n",
        "    neutralValues3[word]+=1"
      ],
      "metadata": {
        "id": "BG4ex4p27lIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#focus on more frequently occuring words for every sentiment=>\n",
        "#sort in DO wrt 2nd column in each of positiveValues,negativeValues and neutralValues\n",
        "\n",
        "df_positive3=pd.DataFrame(sorted(positiveValues3.items(),key=lambda x:x[1],reverse=True))\n",
        "df_negative3=pd.DataFrame(sorted(negativeValues3.items(),key=lambda x:x[1],reverse=True))\n",
        "df_neutral3=pd.DataFrame(sorted(neutralValues3.items(),key=lambda x:x[1],reverse=True))"
      ],
      "metadata": {
        "id": "_ShW47Yp7lLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd1tri=df_positive3[0][:10]\n",
        "pd2tri=df_positive3[1][:10]\n",
        "\n",
        "ned1tri=df_negative3[0][:10]\n",
        "ned2tri=df_negative3[1][:10]\n",
        "\n",
        "nud1tri=df_neutral3[0][:10]\n",
        "nud2tri=df_neutral3[1][:10]\n",
        "\n",
        "plt.figure(1,figsize=(16,4))\n",
        "\n",
        "plt.bar(pd1tri,pd2tri, color ='green',\n",
        "        width = 0.4)\n",
        " \n",
        "plt.xlabel(\"Words in positive dataframe\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Top 10 words in positive dataframe-TRIGRAM ANALYSIS\")\n",
        "\n",
        "plt.savefig(\"positive-trigram.png\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "edFmp0Q87TIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_positive3.head(10)"
      ],
      "metadata": {
        "id": "VMIMrGCe78oL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(1,figsize=(16,4))\n",
        "\n",
        "plt.bar(ned1tri,ned2tri, color ='red',\n",
        "        width = 0.4)\n",
        " \n",
        "plt.xlabel(\"Words in negative dataframe\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Top 10 words in negative dataframe-TRIGRAM ANALYSIS\")\n",
        "\n",
        "plt.savefig(\"negative-trigram.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ascUBpDa78r5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_negative3.head(10)"
      ],
      "metadata": {
        "id": "Dqm4oMzy78vG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(1,figsize=(16,4))\n",
        "\n",
        "plt.bar(nud1tri,nud2tri, color ='yellow',\n",
        "        width = 0.4)\n",
        " \n",
        "plt.xlabel(\"Words in neutral dataframe\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Top 10 words in neutral dataframe-TRIGRAM ANALYSIS\")\n",
        "\n",
        "plt.savefig(\"neutral-trigram.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uSO-PgpN78ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_neutral3.head(10)"
      ],
      "metadata": {
        "id": "y_AmUzqX781t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}